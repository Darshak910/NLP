{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_A02_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darshak910/NLP/blob/master/NLP_A02_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7XwofyH6clm",
        "colab_type": "code",
        "outputId": "29de0221-5a18-45d2-f555-9d656b1b165d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtqWljrxpao5",
        "colab_type": "code",
        "outputId": "3a37282a-6079-4ad0-fde4-660adde196fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Installing pytorch-ignite\n",
        "!pip install pytorch-ignite"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx8ynXrV6fX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all the required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas.plotting import table\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
        "\n",
        "import torch\n",
        "from torch.nn import Conv1d, MaxPool1d, Flatten, Linear\n",
        "from torch.nn import L1Loss, CrossEntropyLoss, Dropout\n",
        "from torch.nn.functional import relu, softmax, sigmoid\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import SGD, Adam, SparseAdam, Adamax\n",
        "from ignite.metrics import Accuracy, Recall, Precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osVA4TfOzSKd",
        "colab_type": "code",
        "outputId": "6a856d75-7e8a-40a6-a2f4-23f9c2ec245e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Reading the dataset and saving to pandas dataframe\n",
        "ds = pd.read_csv('https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv',\n",
        "                 delimiter='\\t')\n",
        "ds.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-eGL2K6_77U",
        "colab_type": "code",
        "outputId": "adb5d48d-cc23-4670-9479-66b41cccc735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Saving only the two required columns\n",
        "ds = ds[['Phrase', 'Sentiment']]\n",
        "ds.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Phrase  Sentiment\n",
              "0  A series of escapades demonstrating the adage ...          1\n",
              "1  A series of escapades demonstrating the adage ...          2\n",
              "2                                           A series          2\n",
              "3                                                  A          2\n",
              "4                                             series          2\n",
              "5  of escapades demonstrating the adage that what...          2\n",
              "6                                                 of          2\n",
              "7  escapades demonstrating the adage that what is...          2\n",
              "8                                          escapades          2\n",
              "9  demonstrating the adage that what is good for ...          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bv_wPw5ecGe",
        "colab_type": "code",
        "outputId": "b0b86c75-65a3-48e8-b32b-f0bf9db873e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ds['Phrase'][1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A series of escapades demonstrating the adage that what is good for the goose'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxRoK0JW7nqt",
        "colab_type": "code",
        "outputId": "3176c490-0781-45bb-816b-d3f9ca19beba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Downloading the stopwords and wordnet corpus\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbJ1S5URcrlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations = \"?:!.,;'\\\"-()/\\\\{}[]|\"\n",
        "\n",
        "# Parameters to adjust to see the impact on outcome\n",
        "remove_stopwords = True\n",
        "use_stemming = True\n",
        "use_lemmatization = False\n",
        "remove_punctuations = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsHU4qyCmDEt",
        "colab_type": "code",
        "outputId": "0430b573-08ba-4669-9a45-1c76df76527c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ds)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156060"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgoP_GhjVXlW",
        "colab_type": "code",
        "outputId": "d850fc3f-18b0-41b2-cda9-2f012428d9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Split the dataset with 70% for Training set and 30% for Testing set\n",
        "# Shuffling the dataset with random state set to 2003\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    ds['Phrase'], ds['Sentiment'], test_size=0.3,\n",
        "    shuffle='True', random_state=2003)\n",
        "\n",
        "train_ds = pd.DataFrame(list(zip(x_train, y_train)), columns=['Phrase', 'Sentiment'])\n",
        "test_ds = pd.DataFrame(list(zip(x_test, y_test)), columns=['Phrase', 'Sentiment'])\n",
        "\n",
        "print(test_ds['Phrase'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                         veteran\n",
            "1                                many definitions\n",
            "2                            a worthwhile glimpse\n",
            "3                               past Seagal films\n",
            "4                                    banal script\n",
            "                           ...                   \n",
            "46813                                the very end\n",
            "46814    self-consciously flashy camera effects ,\n",
            "46815                        a half-hearted fluke\n",
            "46816                       's certainly laudable\n",
            "46817                                 human drama\n",
            "Name: Phrase, Length: 46818, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrhBXGCnc8jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-processing for the Training set\n",
        "X, Y = [], []\n",
        "\n",
        "# For every single label save the Sentiment label\n",
        "for y in range(len(train_ds)):\n",
        "  label = train_ds['Sentiment'][y]\n",
        "  temp_phrase = []\n",
        "\n",
        "  # Split the phrase to words and setting the text to lowercase\n",
        "  space = str(train_ds['Phrase'][y]).lower().split(' ')\n",
        "  # print(space)\n",
        "\n",
        "  # For each word in the Phrase\n",
        "  for word in space:\n",
        "    new_word = word\n",
        "\n",
        "    # Giving conditional procedures according to stopwords and punctuations\n",
        "    if(word in stopwords_en):\n",
        "      continue\n",
        "    if(word in punctuations):\n",
        "      continue\n",
        "    \n",
        "    # Condition specifying if stemming is used or not\n",
        "    if(use_stemming):\n",
        "      # Using either Porter or Lancaster stemming\n",
        "      new_word = porter_stemmer.stem(new_word)\n",
        "      # new_word = lancaster_stemmer.stem(new_word)\n",
        "    \n",
        "    # Condition specifying if lemmatization is used or not\n",
        "    if(use_lemmatization):\n",
        "      new_word = wordnet_lemmatizer.lemmatize(new_word)\n",
        "\n",
        "    # Adding normalized word to a temporary variable\n",
        "    temp_phrase.append(new_word)\n",
        "\n",
        "  # if(not temp_phrase == []):\n",
        "  X.append(temp_phrase)\n",
        "  Y.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXx_7J_diOvS",
        "colab_type": "code",
        "outputId": "ff365426-cf19-49f6-f703-55c7b7920bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109242"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqr1w7axt-pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Joining the phrase\n",
        "for i in range(len(X)):\n",
        "  X[i] = ' '.join(X[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGruaAju8-EC",
        "colab_type": "code",
        "outputId": "9fbe7cfe-7f7b-4c0b-cd8a-268cc37979cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X[2]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fan gross-out comedi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNgCYcudz0Dy",
        "colab_type": "code",
        "outputId": "5a4eed20-47eb-49b2-a3ea-a25f8ee783e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109242"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rLD0Xa7311U",
        "colab_type": "code",
        "outputId": "e2d05bef-ca6f-4635-a914-f32aaa310936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Merging two lists into a tuple using zip() method and converting the lists of\n",
        "# tuples to Pandas DataFrame and setting the column name\n",
        "ds_train = pd.DataFrame(list(zip(X, Y)), columns=['Phrase', 'Sentiment'])\n",
        "\n",
        "# Replacing the blank cells with NaN in the DataFrame\n",
        "ds_train['Phrase'].replace('', np.nan, inplace=True)\n",
        "\n",
        "# Dropping all the NaN values from the DataFrame\n",
        "ds_train.dropna(subset=['Phrase'], inplace=True)\n",
        "\n",
        "len(ds_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSGX3X3-SZ_S",
        "colab_type": "code",
        "outputId": "9de0ef53-da2d-448d-c3db-05ebc0ba0741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "ds_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gorgeou epic</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fan gross-out comedi</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>filmmak ascend liter olympu art world</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twist mysteri</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109237</th>\n",
              "      <td>dull sens faster deeper recreat drug market</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109238</th>\n",
              "      <td>bitter less matur</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109239</th>\n",
              "      <td>play better film 's publicist peopl take mani ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109240</th>\n",
              "      <td>faith</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109241</th>\n",
              "      <td>extent</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108578 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Phrase  Sentiment\n",
              "0                                                     age          2\n",
              "1                                            gorgeou epic          4\n",
              "2                                    fan gross-out comedi          2\n",
              "3                   filmmak ascend liter olympu art world          4\n",
              "4                                           twist mysteri          2\n",
              "...                                                   ...        ...\n",
              "109237        dull sens faster deeper recreat drug market          1\n",
              "109238                                  bitter less matur          1\n",
              "109239  play better film 's publicist peopl take mani ...          1\n",
              "109240                                              faith          2\n",
              "109241                                             extent          2\n",
              "\n",
              "[108578 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0iXJwq1OpQ_",
        "colab_type": "code",
        "outputId": "0bf55da4-3b52-4ace-8fb2-838c15cb1122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Phrases associated to sentiment labels count\n",
        "print(ds_train.Sentiment.value_counts())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2    54977\n",
            "3    23021\n",
            "1    19191\n",
            "4     6468\n",
            "0     4921\n",
            "Name: Sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFtevF-RG-Dz",
        "colab_type": "code",
        "outputId": "f6be258a-be2e-45a1-9271-b176e7006453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Manually counting the number of '0' labelled sentiments\n",
        "count = 0\n",
        "for y in ds_train['Sentiment']:\n",
        "  if(y == 0):\n",
        "    count+=1\n",
        "print(count)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnRnfUzDM_v1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving similar labelled phrases together for resampling\n",
        "y0 = ds_train[ds_train['Sentiment'] == 0]\n",
        "y1 = ds_train[ds_train['Sentiment'] == 1]\n",
        "y2 = ds_train[ds_train['Sentiment'] == 2]\n",
        "y3 = ds_train[ds_train['Sentiment'] == 3]\n",
        "y4 = ds_train[ds_train['Sentiment'] == 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWl4dOesOSNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Randomly down sampling each label to match the count of the lowest label count\n",
        "y00 = resample(y0, replace = True, n_samples = count, random_state = 2003)\n",
        "y01 = resample(y1, replace = True, n_samples = count, random_state = 2003)\n",
        "y02 = resample(y2, replace = True, n_samples = count, random_state = 2003)\n",
        "y03 = resample(y3, replace = True, n_samples = count, random_state = 2003)\n",
        "y04 = resample(y4, replace = True, n_samples = count, random_state = 2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-GmvRiRTXNq",
        "colab_type": "code",
        "outputId": "9b65bfdc-b87f-4726-a995-ea61687bb8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Concatinating the new down sampled dataset\n",
        "ds_train = pd.concat([y00, y01, y02, y03, y04])\n",
        "\n",
        "# ds_train.Sentiment.value_counts()\n",
        "ds_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24605, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkUrItsE1xX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transforming each text into vector of word counts using CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=20000, stop_words=\"english\",\n",
        "                             ngram_range=(1, 2))\n",
        "\n",
        "# Transforming each text into vector of word counts using TfidfVectorizer\n",
        "# vectorizer = TfidfVectorizer(max_features=20000, stop_words=\"english\",\n",
        "#                              ngram_range=(2, 2))\n",
        "\n",
        "x_train = vectorizer.fit_transform(ds_train[\"Phrase\"])\n",
        "y_train = ds_train[\"Sentiment\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAJgZRtGcotE",
        "colab_type": "code",
        "outputId": "f6b33cd3-56c4-4d8d-d9da-ff9d18eef379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape\n",
        "# x_test.shape\n",
        "# X.shape[1]\n",
        "# y_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24605, 20000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFvd3qzwI5al",
        "colab_type": "code",
        "outputId": "0049028b-2378-40fa-e783-12fb69c368d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting into numpy arrays\n",
        "x_train_np = x_train.toarray()\n",
        "y_train_np = np.array(y_train)\n",
        "\n",
        "print(x_train_np.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24605, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK4rEbGqjDm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a class to define our model\n",
        "class CNNMultipleClassifier(torch.nn.Module):\n",
        "  # The initialization method\n",
        "  def __init__(self, batchsize, inputs, outputs):\n",
        "    super(CNNMultipleClassifier, self).__init__()\n",
        "    self.batchsize = batchsize\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "\n",
        "    # Defining the input layer (input channels, output channels, kernels)\n",
        "    self.input_layer = Conv1d(inputs, batchsize, 1)\n",
        "\n",
        "    # Maxpooling layer with kernel size\n",
        "    self.maxpooling_layer = MaxPool1d(1)\n",
        "\n",
        "    # Adding Conv1d layers\n",
        "    self.conv_layer1 = Conv1d(batchsize, 64, 1)\n",
        "    self.conv_layer2 = Conv1d(64, 128, 1)\n",
        "\n",
        "    # A Flatten layer\n",
        "    self.flatten_layer = Flatten()\n",
        "\n",
        "    # A Linear layer with (inputs, outputs)\n",
        "    self.linear_layer1 = Linear(128, 64)\n",
        "    # Adding a dropout layer for reducing overfitting\n",
        "    self.dropout_layer = Dropout(p=0.2)\n",
        "\n",
        "    # Lastly, an Output layer\n",
        "    self.output_layer = Linear(64, outputs)\n",
        "\n",
        "  # A method to feed the model\n",
        "  def feed(self, input):\n",
        "    # Reshape so that it can be fed to input layer\n",
        "    # Although 1D Conv, it expects a 3D array in 1D fashion\n",
        "    input = input.reshape((self.batchsize, self.inputs, 1))\n",
        "\n",
        "    # Run through the Relu\n",
        "    output = relu(self.input_layer(input))\n",
        "\n",
        "    # Get the output of MaxPooling\n",
        "    output = self.maxpooling_layer(output)\n",
        "\n",
        "    # Output of Conv1d layers and passing through Relu\n",
        "    output = relu(self.conv_layer1(output))\n",
        "    output = relu(self.conv_layer2(output))\n",
        "\n",
        "    # Output of flatten layer\n",
        "    output = self.flatten_layer(output)\n",
        "\n",
        "    # Output of Linear layer and pass through Relu\n",
        "    output = relu(self.linear_layer1(output))\n",
        "    # Output of Dropout layer\n",
        "    output = self.dropout_layer(output)\n",
        "\n",
        "    # Lastly, output of Output layer\n",
        "    output = self.output_layer(output)\n",
        "\n",
        "    # Get value between 0 and 1 using Sigmoid\n",
        "    # output = sigmoid(output)\n",
        "\n",
        "    # To get accuracy we get int values of 0 or 1\n",
        "    output_ = torch.round(output)\n",
        "\n",
        "    # Using Softmax\n",
        "    output = softmax(output)\n",
        "\n",
        "    return output, output_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk77xGOspvP1",
        "colab_type": "code",
        "outputId": "9799a66e-072f-4c20-a08f-63166a540079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Defining our model\n",
        "batchsize = 128\n",
        "\n",
        "# (batchsize, x_columns, y_columns)\n",
        "model = CNNMultipleClassifier(batchsize, x_train.shape[1], 5)\n",
        "\n",
        "# Set the model to use GPU\n",
        "model.cuda()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNMultipleClassifier(\n",
              "  (input_layer): Conv1d(20000, 128, kernel_size=(1,), stride=(1,))\n",
              "  (maxpooling_layer): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
              "  (conv_layer2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "  (flatten_layer): Flatten()\n",
              "  (linear_layer1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
              "  (output_layer): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7P2NSZrvCRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method to return L1Loss, Accuracy, Recall and Precision\n",
        "def model_loss(model, dataset, train = False, optimizer = None):\n",
        "  \n",
        "  # Using crossentropy loss for calculating the loss\n",
        "  cross_loss = CrossEntropyLoss()\n",
        "\n",
        "  avg_loss = 0\n",
        "  avg_accuracy = 0\n",
        "  avg_recall = 0\n",
        "  avg_precision = 0\n",
        "  count = 0\n",
        "\n",
        "  for input, output in iter(dataset):\n",
        "    # Get predictions for training dataset\n",
        "    predictions, predictions_ = model.feed(input)\n",
        "    # print(predictions)\n",
        "\n",
        "    # Converting to numpy\n",
        "    a = []\n",
        "    out = output.data.cpu().numpy()\n",
        "    for o in out:\n",
        "      a.append(int(o[0]))\n",
        "\n",
        "    # Taking out the max valued labels\n",
        "    pred, indices = torch.max(predictions, 1)\n",
        "\n",
        "    # Converting to long tensor type \n",
        "    a_list = torch.FloatTensor(a).cuda().long()\n",
        "\n",
        "    # Get the Loss\n",
        "    loss = cross_loss(predictions, a_list)\n",
        "\n",
        "    # Other metric performances using softmax returned output\n",
        "    accuracy = accuracy_score(a, indices.data.cpu())\n",
        "    recall = recall_score(a, indices.data.cpu(), average='macro', zero_division=0)\n",
        "    precision = precision_score(a, indices.data.cpu(), average='macro', zero_division=0)\n",
        "\n",
        "    if(train):\n",
        "      # Clear errors\n",
        "      optimizer.zero_grad()\n",
        "      # Compute the gradients for our optimizer\n",
        "      loss.backward()\n",
        "      # Using optimizer to update model's parameters based on gradients\n",
        "      optimizer.step()\n",
        "    \n",
        "    # Loss\n",
        "    avg_loss += loss.item()\n",
        "\n",
        "    # Other performance metrics\n",
        "    avg_accuracy += accuracy\n",
        "    avg_recall += recall\n",
        "    avg_precision += precision\n",
        "    count += 1\n",
        "  \n",
        "  return avg_loss/count, avg_accuracy/count, avg_recall/count, avg_precision/count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxK3luOgycHn",
        "colab_type": "code",
        "outputId": "6b684154-c530-4d97-fc5c-c645f9b25bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch_history = []\n",
        "f1_score_history = []\n",
        "loss_history = []\n",
        "accuracy_history = []\n",
        "\n",
        "# Training the model\n",
        "epochs = 50\n",
        "# optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# optimizer = Adamax(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Convert training set to torch variables using GPU as float.\n",
        "# The reshape is to remove PyTorch warning\n",
        "inputs = torch.from_numpy(x_train_np).cuda().float()\n",
        "outputs = torch.from_numpy(y_train_np.reshape(y_train_np.shape[0], 1)).cuda().float()\n",
        "\n",
        "# Create DataLoader instance to work with batches\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batchsize, shuffle=True, drop_last=True)\n",
        "\n",
        "# Start training loop\n",
        "for epoch in range(epochs):\n",
        "  # Cycle through batches and get average loss and other metrics\n",
        "  avg_loss, avg_accuracy, avg_recall, avg_precision = model_loss(model, loader, train=True, optimizer=optimizer)\n",
        "  \n",
        "  # Get f1 score\n",
        "  f1 = (2 * (avg_precision * avg_recall)/(avg_precision + avg_recall))\n",
        "\n",
        "  # Saving the history for ploting on graph\n",
        "  epoch_history.append(epoch + 1)\n",
        "  f1_score_history.append(f1)\n",
        "  loss_history.append(avg_loss)\n",
        "  accuracy_history.append(avg_accuracy)\n",
        "\n",
        "  # Printing the loss and other metrics\n",
        "  print(\"Epoch \" + str(epoch + 1) + \n",
        "        \":\\n\\tLoss = \" + str(avg_loss) +\n",
        "        \"\\n\\tAccuracy = \" + str(avg_accuracy) +\n",
        "        \"\\n\\tRecall = \" + str(avg_recall) +\n",
        "        \"\\n\\tPrecision = \" + str(avg_precision) +\n",
        "        \"\\n\\tF1 Score = \" + str(f1))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "\tLoss = 1.4750205775101979\n",
            "\tAccuracy = 0.3989664713541667\n",
            "\tRecall = 0.39958640235859083\n",
            "\tPrecision = 0.32674051224008976\n",
            "\tF1 Score = 0.3595104715703943\n",
            "Epoch 2:\n",
            "\tLoss = 1.339122548699379\n",
            "\tAccuracy = 0.5596923828125\n",
            "\tRecall = 0.5598586754161601\n",
            "\tPrecision = 0.5577843285503955\n",
            "\tF1 Score = 0.5588195769880403\n",
            "Epoch 3:\n",
            "\tLoss = 1.2728646211326122\n",
            "\tAccuracy = 0.6290283203125\n",
            "\tRecall = 0.6288463927360441\n",
            "\tPrecision = 0.6346447731321562\n",
            "\tF1 Score = 0.6317322780467665\n",
            "Epoch 4:\n",
            "\tLoss = 1.230479013795654\n",
            "\tAccuracy = 0.6722412109375\n",
            "\tRecall = 0.6720050094261185\n",
            "\tPrecision = 0.6765285901995611\n",
            "\tF1 Score = 0.6742592127630921\n",
            "Epoch 5:\n",
            "\tLoss = 1.2069270604600508\n",
            "\tAccuracy = 0.6964925130208334\n",
            "\tRecall = 0.696721898515705\n",
            "\tPrecision = 0.6996655194984922\n",
            "\tF1 Score = 0.6981906063923161\n",
            "Epoch 6:\n",
            "\tLoss = 1.1921152354528506\n",
            "\tAccuracy = 0.71142578125\n",
            "\tRecall = 0.7123660673164195\n",
            "\tPrecision = 0.7139975615830035\n",
            "\tF1 Score = 0.7131808813869609\n",
            "Epoch 7:\n",
            "\tLoss = 1.1843682192265987\n",
            "\tAccuracy = 0.71923828125\n",
            "\tRecall = 0.7199175365366998\n",
            "\tPrecision = 0.7222726510951029\n",
            "\tF1 Score = 0.721093170850182\n",
            "Epoch 8:\n",
            "\tLoss = 1.1754666045308113\n",
            "\tAccuracy = 0.7283528645833334\n",
            "\tRecall = 0.728291658450649\n",
            "\tPrecision = 0.7321763903515109\n",
            "\tF1 Score = 0.7302288578580823\n",
            "Epoch 9:\n",
            "\tLoss = 1.1692662369459867\n",
            "\tAccuracy = 0.734619140625\n",
            "\tRecall = 0.7339416394097852\n",
            "\tPrecision = 0.7368766128107417\n",
            "\tF1 Score = 0.7354061977848734\n",
            "Epoch 10:\n",
            "\tLoss = 1.1633130895594757\n",
            "\tAccuracy = 0.740478515625\n",
            "\tRecall = 0.7414507159873799\n",
            "\tPrecision = 0.743274918299878\n",
            "\tF1 Score = 0.7423616964941298\n",
            "Epoch 11:\n",
            "\tLoss = 1.1582073600341876\n",
            "\tAccuracy = 0.7460530598958334\n",
            "\tRecall = 0.7458381699394283\n",
            "\tPrecision = 0.7492862609836898\n",
            "\tF1 Score = 0.7475582394273227\n",
            "Epoch 12:\n",
            "\tLoss = 1.1566122937947512\n",
            "\tAccuracy = 0.7479654947916666\n",
            "\tRecall = 0.7479290855588507\n",
            "\tPrecision = 0.7503814024626999\n",
            "\tF1 Score = 0.7491532371309446\n",
            "Epoch 13:\n",
            "\tLoss = 1.1525498361637194\n",
            "\tAccuracy = 0.7515869140625\n",
            "\tRecall = 0.7504627871261146\n",
            "\tPrecision = 0.7537614754401735\n",
            "\tF1 Score = 0.7521085143541846\n",
            "Epoch 14:\n",
            "\tLoss = 1.147921783849597\n",
            "\tAccuracy = 0.7565511067708334\n",
            "\tRecall = 0.7568103773672111\n",
            "\tPrecision = 0.7591221120493353\n",
            "\tF1 Score = 0.7579644820581295\n",
            "Epoch 15:\n",
            "\tLoss = 1.1453000511974096\n",
            "\tAccuracy = 0.7593180338541666\n",
            "\tRecall = 0.7604406011067907\n",
            "\tPrecision = 0.7621988807165058\n",
            "\tF1 Score = 0.7613187257182217\n",
            "Epoch 16:\n",
            "\tLoss = 1.1427829923729103\n",
            "\tAccuracy = 0.7617594401041666\n",
            "\tRecall = 0.7619238143100527\n",
            "\tPrecision = 0.7647595556438995\n",
            "\tF1 Score = 0.7633390513500334\n",
            "Epoch 17:\n",
            "\tLoss = 1.14420132090648\n",
            "\tAccuracy = 0.7601318359375\n",
            "\tRecall = 0.7601008307496969\n",
            "\tPrecision = 0.7621781956135557\n",
            "\tF1 Score = 0.7611380957526586\n",
            "Epoch 18:\n",
            "\tLoss = 1.1434912600864966\n",
            "\tAccuracy = 0.76123046875\n",
            "\tRecall = 0.7609798720929857\n",
            "\tPrecision = 0.7636936037181399\n",
            "\tF1 Score = 0.7623343228509789\n",
            "Epoch 19:\n",
            "\tLoss = 1.1408735364675522\n",
            "\tAccuracy = 0.7635498046875\n",
            "\tRecall = 0.7634363898665358\n",
            "\tPrecision = 0.7665483272146362\n",
            "\tF1 Score = 0.7649891937527451\n",
            "Epoch 20:\n",
            "\tLoss = 1.139024119824171\n",
            "\tAccuracy = 0.7657063802083334\n",
            "\tRecall = 0.7656061729359517\n",
            "\tPrecision = 0.7695067364412678\n",
            "\tF1 Score = 0.7675514992239119\n",
            "Epoch 21:\n",
            "\tLoss = 1.1372666992247105\n",
            "\tAccuracy = 0.7675374348958334\n",
            "\tRecall = 0.768341807050812\n",
            "\tPrecision = 0.7703091351044197\n",
            "\tF1 Score = 0.7693242133590636\n",
            "Epoch 22:\n",
            "\tLoss = 1.1378995074580114\n",
            "\tAccuracy = 0.7666015625\n",
            "\tRecall = 0.7671469028902536\n",
            "\tPrecision = 0.7686215533967679\n",
            "\tF1 Score = 0.7678835201610972\n",
            "Epoch 23:\n",
            "\tLoss = 1.1357280313968658\n",
            "\tAccuracy = 0.7690836588541666\n",
            "\tRecall = 0.7691093001256423\n",
            "\tPrecision = 0.7729850877378924\n",
            "\tF1 Score = 0.771042323370752\n",
            "Epoch 24:\n",
            "\tLoss = 1.1367029926429193\n",
            "\tAccuracy = 0.7677001953125\n",
            "\tRecall = 0.7671622028690752\n",
            "\tPrecision = 0.7715223879014456\n",
            "\tF1 Score = 0.7693361176365422\n",
            "Epoch 25:\n",
            "\tLoss = 1.135922634974122\n",
            "\tAccuracy = 0.7684733072916666\n",
            "\tRecall = 0.7683271671592152\n",
            "\tPrecision = 0.7722080279125861\n",
            "\tF1 Score = 0.7702627092736153\n",
            "Epoch 26:\n",
            "\tLoss = 1.1352839500953753\n",
            "\tAccuracy = 0.7693684895833334\n",
            "\tRecall = 0.7691610327347966\n",
            "\tPrecision = 0.7723112118912886\n",
            "\tF1 Score = 0.7707329034329256\n",
            "Epoch 27:\n",
            "\tLoss = 1.1330117440472047\n",
            "\tAccuracy = 0.7715657552083334\n",
            "\tRecall = 0.7714944323078252\n",
            "\tPrecision = 0.7741009480543887\n",
            "\tF1 Score = 0.7727954923470479\n",
            "Epoch 28:\n",
            "\tLoss = 1.1310262717306614\n",
            "\tAccuracy = 0.7735188802083334\n",
            "\tRecall = 0.7730163578967547\n",
            "\tPrecision = 0.7763605644497024\n",
            "\tF1 Score = 0.7746848520716253\n",
            "Epoch 29:\n",
            "\tLoss = 1.1292865425348282\n",
            "\tAccuracy = 0.775146484375\n",
            "\tRecall = 0.7752486850582628\n",
            "\tPrecision = 0.7786955138216639\n",
            "\tF1 Score = 0.7769682767066463\n",
            "Epoch 30:\n",
            "\tLoss = 1.1286369698743026\n",
            "\tAccuracy = 0.7762044270833334\n",
            "\tRecall = 0.7766889939726628\n",
            "\tPrecision = 0.7801768420277542\n",
            "\tF1 Score = 0.7784290110855039\n",
            "Epoch 31:\n",
            "\tLoss = 1.1284458159158628\n",
            "\tAccuracy = 0.7762044270833334\n",
            "\tRecall = 0.775188426004162\n",
            "\tPrecision = 0.7790330232360336\n",
            "\tF1 Score = 0.7771059695294115\n",
            "Epoch 32:\n",
            "\tLoss = 1.1274453836182754\n",
            "\tAccuracy = 0.7773030598958334\n",
            "\tRecall = 0.7782118831881535\n",
            "\tPrecision = 0.7809735133085498\n",
            "\tF1 Score = 0.7795902525478791\n",
            "Epoch 33:\n",
            "\tLoss = 1.1258457625905673\n",
            "\tAccuracy = 0.7784830729166666\n",
            "\tRecall = 0.7784768120988107\n",
            "\tPrecision = 0.7813102576945193\n",
            "\tF1 Score = 0.7798909613357927\n",
            "Epoch 34:\n",
            "\tLoss = 1.1248776509116094\n",
            "\tAccuracy = 0.7794596354166666\n",
            "\tRecall = 0.7795364459514973\n",
            "\tPrecision = 0.7819459456936343\n",
            "\tF1 Score = 0.7807393367913533\n",
            "Epoch 35:\n",
            "\tLoss = 1.1223451166103284\n",
            "\tAccuracy = 0.7825520833333334\n",
            "\tRecall = 0.7824111474722412\n",
            "\tPrecision = 0.7855122501781753\n",
            "\tF1 Score = 0.7839586320816392\n",
            "Epoch 36:\n",
            "\tLoss = 1.1224262503286202\n",
            "\tAccuracy = 0.7822265625\n",
            "\tRecall = 0.7815996980988914\n",
            "\tPrecision = 0.7840800853817882\n",
            "\tF1 Score = 0.7828379269959719\n",
            "Epoch 37:\n",
            "\tLoss = 1.1243841915080945\n",
            "\tAccuracy = 0.7803141276041666\n",
            "\tRecall = 0.7806940680619082\n",
            "\tPrecision = 0.7834026756817073\n",
            "\tF1 Score = 0.7820460265708322\n",
            "Epoch 38:\n",
            "\tLoss = 1.1248288185646136\n",
            "\tAccuracy = 0.7799072265625\n",
            "\tRecall = 0.7799069740396901\n",
            "\tPrecision = 0.7831938251697337\n",
            "\tF1 Score = 0.7815469438485775\n",
            "Epoch 39:\n",
            "\tLoss = 1.1270492356270552\n",
            "\tAccuracy = 0.7777506510416666\n",
            "\tRecall = 0.777850827042204\n",
            "\tPrecision = 0.780418941331142\n",
            "\tF1 Score = 0.779132767989871\n",
            "Epoch 40:\n",
            "\tLoss = 1.1267240730424721\n",
            "\tAccuracy = 0.7778727213541666\n",
            "\tRecall = 0.7772401568376922\n",
            "\tPrecision = 0.7810775019445547\n",
            "\tF1 Score = 0.779154104674893\n",
            "Epoch 41:\n",
            "\tLoss = 1.1235754725833733\n",
            "\tAccuracy = 0.7810872395833334\n",
            "\tRecall = 0.781480185692441\n",
            "\tPrecision = 0.7847049180215323\n",
            "\tF1 Score = 0.7830892320391154\n",
            "Epoch 42:\n",
            "\tLoss = 1.1238658210883539\n",
            "\tAccuracy = 0.7805989583333334\n",
            "\tRecall = 0.7805848037162356\n",
            "\tPrecision = 0.7830060376533517\n",
            "\tF1 Score = 0.7817935460339506\n",
            "Epoch 43:\n",
            "\tLoss = 1.1222996575136979\n",
            "\tAccuracy = 0.7822672526041666\n",
            "\tRecall = 0.7812111371019933\n",
            "\tPrecision = 0.7844263513582872\n",
            "\tF1 Score = 0.782815442826466\n",
            "Epoch 44:\n",
            "\tLoss = 1.121927123516798\n",
            "\tAccuracy = 0.7823893229166666\n",
            "\tRecall = 0.783060708710044\n",
            "\tPrecision = 0.785096913169137\n",
            "\tF1 Score = 0.784077488965147\n",
            "Epoch 45:\n",
            "\tLoss = 1.1223121993243694\n",
            "\tAccuracy = 0.7823486328125\n",
            "\tRecall = 0.7816722278926654\n",
            "\tPrecision = 0.7860097462881567\n",
            "\tF1 Score = 0.7838349864901167\n",
            "Epoch 46:\n",
            "\tLoss = 1.1211450286209583\n",
            "\tAccuracy = 0.78369140625\n",
            "\tRecall = 0.784140139719001\n",
            "\tPrecision = 0.7867883260266472\n",
            "\tF1 Score = 0.7854620007881452\n",
            "Epoch 47:\n",
            "\tLoss = 1.1195531866202753\n",
            "\tAccuracy = 0.7850748697916666\n",
            "\tRecall = 0.7851075371000609\n",
            "\tPrecision = 0.7882012871241768\n",
            "\tF1 Score = 0.7866513703414681\n",
            "Epoch 48:\n",
            "\tLoss = 1.1247904331733782\n",
            "\tAccuracy = 0.77978515625\n",
            "\tRecall = 0.7802997134709516\n",
            "\tPrecision = 0.7823458714118625\n",
            "\tF1 Score = 0.781321452802285\n",
            "Epoch 49:\n",
            "\tLoss = 1.1211908583839734\n",
            "\tAccuracy = 0.783447265625\n",
            "\tRecall = 0.7837637034762466\n",
            "\tPrecision = 0.7869205535327376\n",
            "\tF1 Score = 0.7853389560965957\n",
            "Epoch 50:\n",
            "\tLoss = 1.1228922487547\n",
            "\tAccuracy = 0.7816569010416666\n",
            "\tRecall = 0.7812224330359195\n",
            "\tPrecision = 0.7852887770184007\n",
            "\tF1 Score = 0.7832503273268546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrry5fT7kMtf",
        "colab_type": "code",
        "outputId": "fe622f40-3a37-43a7-cd3b-4f77c7ecbb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Saving model\n",
        "torch.save(model, '1101352_1dconv_reg.pt') "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type CNNMultipleClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvUFQ1m3kSOu",
        "colab_type": "code",
        "outputId": "14a3c14d-16e5-4f12-cdab-c359425244c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Loading model\n",
        "model = torch.load('1101352_1dconv_reg.pt')\n",
        "model.eval()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNMultipleClassifier(\n",
              "  (input_layer): Conv1d(20000, 128, kernel_size=(1,), stride=(1,))\n",
              "  (maxpooling_layer): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
              "  (conv_layer2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "  (flatten_layer): Flatten()\n",
              "  (linear_layer1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
              "  (output_layer): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAaCWLgm_ClT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e65e72dd-6185-4343-f30c-e15a070d83c6"
      },
      "source": [
        "# Plotting Accuracy and F1 score together\n",
        "plt.plot(epoch_history, accuracy_history, label='Accuracy')\n",
        "plt.plot(epoch_history, f1_score_history, label='F1 score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Graph for Loss w.r.t Epoch\n",
        "plt.plot(epoch_history, loss_history, label='Loss', color='red')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRNKcgkBEJM0pCERE0tz/DxLHWERrZTkgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiI5KSBERCQnBYSIiOSkgBARkZz+P2q5NTvWcWvdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tsxK3pjmGML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-processing for the Testing set\n",
        "X, Y = [], []\n",
        "\n",
        "# For every single label save the Sentiment label\n",
        "for y in range(len(test_ds)):\n",
        "  label = test_ds['Sentiment'][y]\n",
        "  temp_phrase = []\n",
        "\n",
        "  # Splitting the pharase to words and setting the text to lowercase\n",
        "  space = str(test_ds['Phrase'][y]).lower().split(' ')\n",
        "  # print(space)\n",
        "\n",
        "  # For each word in the Phrase\n",
        "  for word in space:\n",
        "    new_word = word\n",
        "\n",
        "    # Giving conditional procedures according to stopwords and punctuations\n",
        "    if(word in stopwords_en):\n",
        "      continue\n",
        "    if(word in punctuations):\n",
        "      continue\n",
        "    \n",
        "    # Condition specifying if stemming is used or not\n",
        "    if(use_stemming):\n",
        "      # Using either Porter or Lancaster stemming\n",
        "      new_word = porter_stemmer.stem(new_word)\n",
        "      # new_word = lancaster_stemmer.stem(new_word)\n",
        "    \n",
        "    # Condition specifying if lemmatization is used or not\n",
        "    if(use_lemmatization):\n",
        "      new_word = wordnet_lemmatizer.lemmatize(new_word)\n",
        "\n",
        "    # Adding normalized word to a temporary variable\n",
        "    temp_phrase.append(new_word)\n",
        "\n",
        "  # if(not temp_phrase == []):\n",
        "  X.append(temp_phrase)\n",
        "  Y.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_ub9ioknD5q",
        "colab_type": "code",
        "outputId": "47d16241-751b-467c-edd2-c038a0fc68ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UI1_e7XnDKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Joining the phrase\n",
        "for i in range(len(X)):\n",
        "  X[i] = ' '.join(X[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCwqARV7nMni",
        "colab_type": "code",
        "outputId": "0630eb58-b2b3-427b-f9d3-2d2a1af2fb3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X[2]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worthwhil glimps'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5b4DQaqnN1O",
        "colab_type": "code",
        "outputId": "f9b88d01-a3e3-43be-af3f-6fe7ed17459d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM-7RkNVnPUp",
        "colab_type": "code",
        "outputId": "05a3be3b-eee6-4023-efeb-e79303bb3424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Merging two lists into a tuple using zip() method and converting the lists of\n",
        "# tuples to Pandas DataFrame and setting the column name\n",
        "ds_test = pd.DataFrame(list(zip(X, Y)), columns=['Phrase', 'Sentiment'])\n",
        "\n",
        "# Replacing the blank cells with NaN in the DataFrame\n",
        "ds_test['Phrase'].replace('', np.nan, inplace=True)\n",
        "\n",
        "# Dropping all the NaN values from the DataFrame\n",
        "ds_test.dropna(subset=['Phrase'], inplace=True)\n",
        "\n",
        "# ds_test.head()\n",
        "len(ds_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UponSGNgns9N",
        "colab_type": "code",
        "outputId": "145d3c7a-26a9-46c0-ebd4-6d7dd5436116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(ds_test.Sentiment.value_counts())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2    23730\n",
            "3     9859\n",
            "1     8062\n",
            "4     2738\n",
            "0     2151\n",
            "Name: Sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IPQUnBQvXH1",
        "colab_type": "code",
        "outputId": "b175289d-4937-4c77-f078-43a884e948d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ds_test.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46540, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f0U-ivsoA3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorizing the phrases\n",
        "x_test = vectorizer.transform(ds_test[\"Phrase\"])\n",
        "y_test = ds_test[\"Sentiment\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgnGrJw_obY0",
        "colab_type": "code",
        "outputId": "a73c79c9-12a5-4afd-8c1c-00d93007569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting to numpy arrays\n",
        "x_test_np = x_test.toarray()\n",
        "y_test_np = np.array(y_test)\n",
        "\n",
        "print(x_test_np.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(46540, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpyCtNwLqasd",
        "colab_type": "code",
        "outputId": "bf9a6451-bd18-4dec-b98b-476b5de26509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Test the model\n",
        "inputs = torch.from_numpy(x_test_np).cuda().float()\n",
        "outputs = torch.from_numpy(y_test_np.reshape(y_test_np.shape[0], 1)).cuda().float()\n",
        "\n",
        "# Create DataLoader instance to work with batches\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batchsize, shuffle=True, drop_last=True)\n",
        "\n",
        "# Cycle through batches and get average loss and other metrics\n",
        "avg_loss, avg_accuracy, avg_recall, avg_precision = model_loss(model, loader)\n",
        "\n",
        "# Get f1 score\n",
        "f1 = (2 * (avg_recall * avg_precision)/(avg_recall + avg_precision))\n",
        "\n",
        "# Printing the loss and other metrics\n",
        "print(\"Testing Loss = \" + str(avg_loss) +\n",
        "    \"\\nTesting Accuracy = \" + str(avg_accuracy) + \n",
        "    \"\\nTesting Recall = \" + str(avg_recall) + \n",
        "    \"\\nTesting Precision = \" + str(avg_precision) + \n",
        "    \"\\nTesting F1 Score = \" + str(f1))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing Loss = 1.3765867074987448\n",
            "Testing Accuracy = 0.5275697314049587\n",
            "Testing Recall = 0.4969638533926106\n",
            "Testing Precision = 0.43905469981362255\n",
            "Testing F1 Score = 0.46621792852740385\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}