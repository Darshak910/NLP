{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_A01",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMHqQufB6oa2dEKfRIvoXqD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darshak910/NLP/blob/master/NLP_A01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a_Xn21Kqfh5",
        "colab_type": "text"
      },
      "source": [
        "# **Regression using a multi layered 1D convolution network in PyTorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "athcPdpfrMMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkaDaVcGqGBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V14LbwD6rhul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = pd.read_csv('/content/housing.csv')\n",
        "# dropping the NA/empty cells\n",
        "ds = ds.dropna() \n",
        "\n",
        "ds.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnrUI2VWrvTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = ds['median_house_value']\n",
        "X = ds.loc[:, 'longitude':'median_income']\n",
        "# X.head()\n",
        "# Y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK9HDcDdtuUB",
        "colab_type": "text"
      },
      "source": [
        "**Splitting it into training and testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf1gTm-_sC77",
        "colab_type": "code",
        "outputId": "e3dabd63-a636-4c9d-81d5-34362afdd211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
        "\n",
        "x_train_np = x_train.to_numpy()\n",
        "y_train_np = y_train.to_numpy()\n",
        "x_test_np = x_test.to_numpy()\n",
        "y_test_np = y_test.to_numpy()\n",
        "\n",
        "print(\"Training: \" + str(x_train_np.size) + \"\\nTesting: \" + str(x_test_np.size))"
      ],
      "execution_count": 643,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: 114424\n",
            "Testing: 49040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cek4DDBt4j1",
        "colab_type": "text"
      },
      "source": [
        "**Creating the network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YtmvF5Et2Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "from torch.nn import Conv1d\n",
        "from torch.nn import MaxPool1d\n",
        "from torch.nn import Flatten\n",
        "from torch.nn import Linear\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "# Importing DataLoader and TensorDataset libraries from PyTorch to work with our datasets\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-V9je8Tuwcg",
        "colab_type": "text"
      },
      "source": [
        "**Defining our Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4k6yYO_uzpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNRegression(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, batch_size, inputs, outputs):\n",
        "    super(CNNRegression, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "\n",
        "    # (input channels, output channels, kernel size)\n",
        "    self.input_layer = Conv1d(inputs, batch_size, 1)\n",
        "\n",
        "    # maxpooling layer (kernel size)\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "\n",
        "    # Another convolution layer\n",
        "    self.conv_layer = Conv1d(batch_size, 32, 1)\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "    self.conv_layer = Conv1d(32, 64, 1)\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "    self.conv_layer = Conv1d(64, 128, 1)\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "    self.flatten_layer = Flatten()\n",
        "\n",
        "    # (inputs, outputs)\n",
        "    self.linear_layer = Linear(128, 64)\n",
        "\n",
        "    # output layer\n",
        "    self.output_layer = Linear(64, outputs)\n",
        "\n",
        "  def feed(self, input):\n",
        "    # reshaping the entry\n",
        "    # although we are using 1D conv, it still expects a 3D array to process in a 1D fashion\n",
        "    input = input.reshape((self.batch_size, self.inputs, 1))\n",
        "\n",
        "    output = relu(self.input_layer(input))\n",
        "\n",
        "    output = self.max_pooling_layer(output)\n",
        "\n",
        "    output = relu(self.conv_layer(output))\n",
        "  \n",
        "    output = self.flatten_layer(output)\n",
        "\n",
        "    output = self.linear_layer(output)\n",
        "\n",
        "    output = self.output_layer(output)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdeYdsv_yVvq",
        "colab_type": "text"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VP0OM4YyU21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import SGD\n",
        "from torch.optim import Adam\n",
        "from torch.optim import Adamax\n",
        "from torch.nn import L1Loss\n",
        "\n",
        "### !pip install pytorch-ignite\n",
        "!pip install pytorch-ignite\n",
        "### importing R^2 package\n",
        "from ignite.contrib.metrics.regression.r2_score import R2Score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IrxDkbtyxdJ",
        "colab_type": "text"
      },
      "source": [
        "**Defining our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy3jNLau1SR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "# (batch_size, X columns, Y columns)\n",
        "model = CNNRegression(batch_size, X.shape[1], 1)\n",
        "\n",
        "# setting the mode for GPU\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL3iukEQ1nTx",
        "colab_type": "text"
      },
      "source": [
        "**Training and testing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGT6z-kw1lzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_loss(model, ds, train = False, optimizer = None):\n",
        "  performance = L1Loss()\n",
        "  score_metric = R2Score()\n",
        "\n",
        "  avg_loss = 0\n",
        "  avg_score = 0\n",
        "  count = 0\n",
        "  for input, output in iter(ds):\n",
        "    # model's predictions for training model\n",
        "    predictions = model.feed(input)\n",
        "\n",
        "    # get model's loss\n",
        "    loss = performance(predictions, output)\n",
        "\n",
        "    # get model's R2 score\n",
        "    score_metric.update([predictions, output])\n",
        "    score = score_metric.compute()\n",
        "\n",
        "    if(train):\n",
        "      # clear any errors\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # compute gradients for our optimizer\n",
        "      loss.backward()\n",
        "\n",
        "      # use the optimizer to update the model's parameters based on the gradients\n",
        "      optimizer.step()\n",
        "\n",
        "    # store the loss and update the counter\n",
        "    avg_loss += loss.item()\n",
        "    avg_score += score\n",
        "    count += 1\n",
        "  \n",
        "  return avg_loss / count, avg_score / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB5NHjo03nT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 200\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr = 1e-3)\n",
        "\n",
        "# converting training set into torch variables using GPU as floats. Reshape is \n",
        "# to remove a warning pytorch outputs\n",
        "inputs = torch.from_numpy(x_train_np).cuda().float()\n",
        "outputs = torch.from_numpy(y_train_np.reshape(y_train_np.shape[0], 1)).cuda().float()\n",
        "\n",
        "# Creating a DataLoader\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batch_size, shuffle=True, drop_last=True)\n",
        "epoch_history = []\n",
        "r2_history = []\n",
        "loss_history = []\n",
        "# Start the training loop\n",
        "for epoch in range(epochs):\n",
        "  avg_loss, avg_r2_score = model_loss(model, loader, train=True, optimizer=optimizer)\n",
        "  epoch_history.append(epoch + 1)\n",
        "  r2_history.append(avg_r2_score)\n",
        "  loss_history.append(avg_loss  )\n",
        "  print(\"Epoch \" + str(epoch + 1) + \":\\n\\tLoss = \" + str(avg_loss) + \"\\n\\tR^2 Score = \" + str(avg_r2_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUze29p2kzKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epoch_history, r2_history, label='Epoch to R2', color='red')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_history, loss_history, label='Loss w.r.t Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaxhbMs46zbX",
        "colab_type": "text"
      },
      "source": [
        "**Testing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTfWaMvp6yP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = torch.from_numpy(x_test_np).cuda().float()\n",
        "outputs = torch.from_numpy(y_test_np.reshape(y_test_np.shape[0], 1)).cuda().float()\n",
        "\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "avg_loss, avg_r2_score = model_loss(model, loader)\n",
        "print(\"The model's l1 loss is: \" + str(avg_loss))\n",
        "print(\"The model's R^2 score is: \" + str(avg_r2_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkxfrBfoqy5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplot(9, 1, 1)\n",
        "plt.plot(ds['longitude'])\n",
        "plt.legend(['longitude'])\n",
        "plt.subplot(9, 1, 2)\n",
        "plt.plot(ds['latitude'], color='red')\n",
        "plt.legend(['latitude'])\n",
        "plt.subplot(9, 1, 3)\n",
        "plt.plot(ds['housing_median_age'], color='green')\n",
        "plt.legend(['housing_median_age'])\n",
        "plt.subplot(9, 1, 4)\n",
        "plt.plot(ds['total_rooms'], color='yellow')\n",
        "plt.legend(['total_rooms'])\n",
        "plt.subplot(9, 1, 5)\n",
        "plt.plot(ds['total_bedrooms'], color='orange')\n",
        "plt.legend(['total_bedrooms'])\n",
        "plt.subplot(9, 1, 6)\n",
        "plt.plot(ds['population'], color='black')\n",
        "plt.legend(['population'])\n",
        "plt.subplot(9, 1, 7)\n",
        "plt.plot(ds['households'], color='purple')\n",
        "plt.legend(['households'])\n",
        "plt.subplot(9, 1, 8)\n",
        "plt.plot(ds['median_income'], color='brown')\n",
        "plt.legend(['median_income'])\n",
        "plt.subplot(9, 1, 9)\n",
        "plt.plot(ds['median_house_value'], color='cyan')\n",
        "plt.legend(['median_house_value'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}